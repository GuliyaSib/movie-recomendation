name: Download Dataset from Kaggle

on:
  push

jobs:
  download-dataset:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          # Use Git LFS to download large files
          submodules: 'recursive'
          fetch-depth: 0
          lfs: true
      - name: Install Kaggle API
        run: pip install kaggle
      - name: Download dataset from Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p data
          kaggle datasets download -d rounakbanik/the-movies-dataset -p data/
          echo "dataset_downloaded=true" >> $GITHUB_ENV
      - name: Unzip dataset
        run: unzip -qo data/*.zip -d data/
      - name: Upload CSV files as artifact - 1
        uses: actions/upload-artifact@v3.1.2
        with:
          name: csv-files
          path: |
            data/*.csv
      - name: Install Python
        uses: actions/setup-python@v4.6.0
        with:
          python-version: 3.9
      - name: Upgrade pip
        run: pip install --upgrade pip
      - name: Install dependencies
        run: pip install -r req.txt
      - name: Preprocessing
        run: |
          python preprocess.py
      - name: Upload a Build Artifact - 2
        uses: actions/upload-artifact@v3.1.2
        with:
          name: preprocess_file
          path: data.csv

  train_model:
    runs-on: ubuntu-latest
    steps:
      - name: Download_prep 
        uses: actions/download-artifact@v3
        with:
          name: preprocess_file

      - name: Install dependencies
        run: pip install -r req.txt

      - name: train model
        run: |
          py model.py

      - name: Upload a Build Artifact - 2
        uses: actions/upload-artifact@v3.1.2
        with:
          name: trained_model
          path: model1
